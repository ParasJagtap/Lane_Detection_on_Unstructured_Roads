import cv2
import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2

class RoadSegmentationDataset(torch.utils.data.Dataset):
    def __init__(self, image_dir, mask_dir, transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.image_files = sorted(os.listdir(image_dir))
        self.mask_files = sorted(os.listdir(mask_dir))

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image = cv2.cvtColor(cv2.imread(os.path.join(self.image_dir, self.image_files[idx])), cv2.COLOR_BGR2RGB)
        mask = cv2.imread(os.path.join(self.mask_dir, self.mask_files[idx]), cv2.IMREAD_GRAYSCALE)

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        return image.float(), mask.float()

def get_augmentations(aug_config):
    transforms = []
    if 'HorizontalFlip' in aug_config:
        transforms.append(A.HorizontalFlip(p=aug_config['HorizontalFlip']))
    if 'VerticalFlip' in aug_config:
        transforms.append(A.VerticalFlip(p=aug_config['VerticalFlip']))
    if 'RandomBrightnessContrast' in aug_config:
        transforms.append(A.RandomBrightnessContrast(
            brightness_limit=0.1,
            contrast_limit=0.1,
            p=aug_config['RandomBrightnessContrast']
        ))
    transforms.append(ToTensorV2())
    return A.Compose(transforms)